{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport io\nimport codecs\nimport os\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:21.538272Z","iopub.execute_input":"2022-02-01T08:29:21.538927Z","iopub.status.idle":"2022-02-01T08:29:21.563393Z","shell.execute_reply.started":"2022-02-01T08:29:21.538837Z","shell.execute_reply":"2022-02-01T08:29:21.562728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load doc into memory\ndef load_doc(filename):\n    with io.open(filename, 'r', encoding='utf8') as f:\n        text = f.read()\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:25.311687Z","iopub.execute_input":"2022-02-01T08:29:25.312354Z","iopub.status.idle":"2022-02-01T08:29:25.316878Z","shell.execute_reply.started":"2022-02-01T08:29:25.312306Z","shell.execute_reply":"2022-02-01T08:29:25.316143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# turn a doc into clean tokens\ndef clean_doc(doc):\n    # replace '--' with a space ' '\n    doc = doc.replace('?', ' ? ')\n    doc = doc.replace('।', ' । ')\n    doc = doc.replace(',', ' । ')\n    doc = doc.replace('-', ' । ')\n    doc = doc.replace('(', ' । ')\n    doc = doc.replace(')', ' । ')\n    doc = doc.replace('{', ' । ')\n    doc = doc.replace('}', ' । ')\n    doc = doc.replace('[', ' । ')\n    doc = doc.replace(']', ' । ')\n    doc = doc.replace('*', ' ')\n    doc = doc.replace('^', ' ')\n    doc = doc.replace('#', ' ')\n    doc = doc.replace('~', ' ')\n    doc = doc.replace('`', ' ')\n    doc = doc.replace('/', ' ')\n    doc = doc.replace('_', ' ')\n    doc = doc.replace('’', ' ')\n    doc = doc.replace('‘', ' ')\n    doc = doc.replace('.',' । ')\n    \n    \n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation from each token\n    #table = str.maketrans('', '', string.punctuation)\n    #tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    #tokens = [word for word in tokens if word.isalpha()]\n    # make lower case\n    tokens = [word.lower() for word in tokens]\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:27.771496Z","iopub.execute_input":"2022-02-01T08:29:27.772003Z","iopub.status.idle":"2022-02-01T08:29:27.781193Z","shell.execute_reply.started":"2022-02-01T08:29:27.771966Z","shell.execute_reply":"2022-02-01T08:29:27.780464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save tokens to file, one dialog per line\ndef save_doc(lines, filename):\n\tdata = '\\n'.join(lines)\n\tfile = open(filename, 'w', encoding='utf8')\n\tfile.write(data)\n\tfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:32.024519Z","iopub.execute_input":"2022-02-01T08:29:32.025233Z","iopub.status.idle":"2022-02-01T08:29:32.030424Z","shell.execute_reply.started":"2022-02-01T08:29:32.025186Z","shell.execute_reply":"2022-02-01T08:29:32.029654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load document\nin_filename = r'../input/bangla-final-nstu/bangla_final_nstu.txt'\ndoc = load_doc(in_filename)\nprint(doc[:200])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:35.901557Z","iopub.execute_input":"2022-02-01T08:29:35.902236Z","iopub.status.idle":"2022-02-01T08:29:35.937579Z","shell.execute_reply.started":"2022-02-01T08:29:35.902195Z","shell.execute_reply":"2022-02-01T08:29:35.936849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean document\n\ntokens = clean_doc(doc)\n#tokens = doc\nprint(tokens[:200])\nprint('Total Tokens: %d' % len(tokens))\nprint('Unique Tokens: %d' % len(set(tokens)))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:39.9818Z","iopub.execute_input":"2022-02-01T08:29:39.982739Z","iopub.status.idle":"2022-02-01T08:29:40.026709Z","shell.execute_reply.started":"2022-02-01T08:29:39.982699Z","shell.execute_reply":"2022-02-01T08:29:40.025954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# organize into sequences of tokens\nlength = 5 + 1\nsequences = list()\nfor i in range(length, len(tokens)):\n\t# select sequence of tokens\n\tseq = tokens[i-length:i]\n\t# convert into a line\n\tline = ' '.join(seq)\n\t# store\n\tsequences.append(line)\nprint('Total Sequences: %d' % len(sequences))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:29:52.499519Z","iopub.execute_input":"2022-02-01T08:29:52.500232Z","iopub.status.idle":"2022-02-01T08:29:52.557312Z","shell.execute_reply.started":"2022-02-01T08:29:52.500196Z","shell.execute_reply":"2022-02-01T08:29:52.556545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save sequences to file\nout_filename = r'./5gram_tokenizer.txt'\nsave_doc(sequences, out_filename)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:30:07.046214Z","iopub.execute_input":"2022-02-01T08:30:07.046717Z","iopub.status.idle":"2022-02-01T08:30:07.062451Z","shell.execute_reply.started":"2022-02-01T08:30:07.046679Z","shell.execute_reply":"2022-02-01T08:30:07.061586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}